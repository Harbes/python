#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
%不显示日期
\date{}

%自动换行
\XeTeXlinebreaklocale "zh" 
\XeTeXlinebreakskip = 0pt plus 1pt
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language chinese-simplified
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "微软雅黑"
\font_sans "default" "楷体"
\font_typewriter "default" "楷体"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format pdf4
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5page%
\topmargin 5pheight%
\rightmargin 2.5page%
\bottommargin 5pheight%
\headheight 2.5pheight%
\headsep 2.5pheight%
\footskip 2.5pheight%
\secnumdepth 3
\tocdepth 1
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
econometric modelling with time series：specification, estimation, and test
 学习笔记
\end_layout

\begin_layout Author
由Harbes整理
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Chapter
the maximum likelihood principle
\end_layout

\begin_layout Chapter
properties of maximum likelihood estimators
\end_layout

\begin_layout Section
introduction
\end_layout

\begin_layout Itemize
在regularity conditions下，MLE具有很多优良的性质：
\end_layout

\begin_deeper
\begin_layout Itemize
大样本下，一致、有效、正态分布
\end_layout

\begin_layout Itemize
小样本下，满足invariance property，是function of sufficient statistics，部分情况下是无偏且唯一的。
\end_layout

\end_deeper
\begin_layout Section
preliminaries
\end_layout

\begin_layout Enumerate
先简介一些时间序列的随机模型，简单讨论其性质
\end_layout

\begin_layout Enumerate
弱大数定理
\end_layout

\begin_layout Enumerate
the scaling factor ensuring convergence of scaled random variables to non-degene
rate distributions
\end_layout

\begin_layout Enumerate
中心极限定理：
\end_layout

\begin_deeper
\begin_layout Enumerate
Linderberg-Levy
\end_layout

\begin_layout Enumerate
Linderberg-Feller
\end_layout

\begin_layout Enumerate
the martingle difference sequence central limit theorem
\end_layout

\begin_layout Enumerate
a mixing central limit theorem
\end_layout

\end_deeper
\begin_layout Subsection
stochastic time series models and their properties
\end_layout

\begin_layout Subsubsection
平稳性：严平稳、弱平稳与non-stationary
\end_layout

\begin_layout Enumerate
弱平稳：对任意有限的j，联合分布函数
\begin_inset Formula $F(y_{1},y_{2},...,y_{j})$
\end_inset

的前两阶unconditional moments不依赖于时间t
\end_layout

\begin_deeper
\begin_layout Itemize
exmple 2.1：stationary AR(1) model
\end_layout

\begin_layout Standard
\begin_inset Formula $y_{t}=\alpha+\rho y_{t-1}+u_{t}$
\end_inset

,
\begin_inset Formula $u_{t}\sim iid(0,\sigma^{2})$
\end_inset

,
\begin_inset Formula $|\rho|<1$
\end_inset


\end_layout

\begin_layout Standard
平稳的原因在于
\begin_inset Formula 
\begin{align*}
 & \mu=E[y_{t}]=\frac{\alpha}{1-\rho}\\
 & \sigma^{2}=E[(y_{t}-\mu)^{2}]=\frac{\sigma^{2}}{1-\rho^{2}}\\
 & \gamma_{k}=E[(y_{t}-\mu)(y_{t-k}-\mu)]=\frac{\sigma^{2}}{1-\rho^{2}}\rho^{k}
\end{align*}

\end_inset


\end_layout

\begin_layout Enumerate
严平稳
\end_layout

\begin_deeper
\begin_layout Itemize
严平稳所有高阶矩都不是时间t的函数
\end_layout

\begin_layout Itemize
严平稳并不要求前两阶矩有限
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection
Martingale difference sequence
\end_layout

\begin_layout Standard
a martingale difference sequence （mds）：一阶条件矩满足
\begin_inset Formula 
\[
E_{t-1}[y_{t}]=E[y_{t}|y_{t-1},y_{t-2},...]=0\tag{2.1}
\]

\end_inset

上式表明时间
\begin_inset Formula $t-1$
\end_inset

的信息不能用于预测
\begin_inset Formula $y_{t}$
\end_inset

。由(2.1)可以推导两个性质：
\begin_inset Formula 
\[
\begin{split}Property\,1: & \quad E[y_{t}]=E[E_{t-1}[y_{t}]]=E[0]=0\\
Property\,2: & \quad E[y_{t}y_{t-k}]=E[E_{t-1}[y_{t}y_{t-k}]]=E[y_{t-k}E_{t-1}[y_{t}]]=E[y_{t-k}\times0]=0
\end{split}
\]

\end_inset

第一个属性说明，mds的无条件期望值为0；第二个属性说明，mds中任意一个时间点的观测与过去线性无关（但是可能存在higher-order moment
 dependence，例如下面的两个例子）
\end_layout

\begin_layout Itemize
example 2.2：nonlinear time series
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $y_{t}=u_{t}u_{t-1}$
\end_inset

,
\begin_inset Formula $u_{t}\sim iid(0,\sigma^{2})$
\end_inset

，
\begin_inset Formula $y_{t}$
\end_inset

是mds的原因在于
\begin_inset Formula $E_{t-1}[y_{t}]=E_{t-1}[u_{t}u_{t-1}]=E_{t-1}[u_{t}]u_{t-1}=0$
\end_inset


\end_layout

\begin_layout Standard
但是该过程存在dependence in the higher order moments：
\begin_inset Formula 
\begin{align*}
cov(y_{t}^{2},y_{t-1}^{2}) & =E[y_{t}^{2}y_{t-1}^{2}]-E[y_{t}^{2}]E[y_{t-1}^{2}]=E[u_{t}^{2}u_{t-1}^{4}u_{t-2}^{2}]-E[u_{t}^{2}u_{t-1}^{2}]E[u_{t-1}^{2}u_{t-2}^{2}]\\
 & =E[u_{t}^{2}]E[u_{t-1}^{4}]E[u_{t-2}^{2}]-E[u_{t}^{2}]E[u_{t-1}^{2}]^{2}E[u_{t-2}^{2}]=\sigma^{4}(E[u_{t-1}^{4}]-\sigma^{4})\neq0
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
example 2.3: autoregression conditional heteroskedasticity
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $y_{t}=z_{t}\sqrt{\alpha_{0}+\alpha_{1}y_{t-1}^{2}}$
\end_inset

,
\begin_inset Formula $z_{t}\sim iid\,N(0,1)$
\end_inset

。
\begin_inset Formula $y_{t}$
\end_inset

是mds的原因在于
\begin_inset Formula $E_{t-1}[y_{t}]=E_{t-1}[z_{t}\sqrt{\alpha_{0}+\alpha_{1}y_{t-1}^{2}}]=E_{t-1}[z_{t}]\sqrt{\alpha_{0}+\alpha_{1}y_{t-1}^{2}}=0$
\end_inset

；但是存在dependence in the second moment
\begin_inset Formula $E_{t-1}[y_{t}^{2}]=E_{t-1}[z_{t}^{2}(\alpha_{0}+\alpha_{1}y_{t-1}^{2})]=E_{t-1}[z_{t}^{2}](\alpha_{0}+\alpha_{1}y_{t-1}^{2})=\alpha_{0}+\alpha_{1}y_{t-1}^{2}$
\end_inset

（条件方差存在且不为0）
\end_layout

\end_deeper
\begin_layout Subsubsection
White Noise
\end_layout

\begin_layout Itemize
前两阶无条件矩满足以下三个性质：
\end_layout

\begin_deeper
\begin_layout Itemize
Property 1：
\begin_inset Formula $E[y_{t}]=0$
\end_inset


\end_layout

\begin_layout Itemize
Property 2：
\begin_inset Formula $E[y_{t}^{2}]=\sigma^{2}<\infty$
\end_inset


\end_layout

\begin_layout Itemize
Property 3：
\begin_inset Formula $E[y_{t}y_{t-k}]=0$
\end_inset

,
\begin_inset Formula $k>0$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
example 2.4: bilinear time series
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $y_{t}=u_{t}+\delta u_{t-1}u_{t-2}$
\end_inset

,
\begin_inset Formula $u_{t}\sim iid(0,\sigma^{2})$
\end_inset

。
\begin_inset Formula $y_{t}$
\end_inset

是白噪声的原因在于
\begin_inset Formula 
\begin{align*}
 & E[y_{t}]=E[u_{t}+\delta u_{t-1}u_{t-2}]=E[u_{t}]+\delta E[u_{t-1}]E[u_{t-2}]=0\\
 & E[y_{t}^{2}]=E[(u_{t}+\delta u_{t-1}u_{t-2})^{2}]=E[u_{t}^{2}+\delta^{2}u_{t-1}^{2}u_{t-2}^{2}+2\delta u_{t}u_{t-1}u_{t-2}]=\sigma^{2}(1+\delta^{2}\sigma^{2})<\infty\\
 & E[y_{t}y_{t-k}]=E[(u_{t}+\delta u_{t-1}u_{t-2})(u_{t-k}+\delta u_{t-1-k}u_{t-2-k})]\\
 & \quad\quad\quad\quad\,=E[u_{t}u_{t-k}+\delta u_{t-1}u_{t-2}u_{t-k}+\delta u_{t}u_{t-1}u_{t-2-k}+\delta^{2}u_{t-1}u_{t-2}u_{t-1-k}u_{t-2-k}]=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
【注意】
\begin_inset Formula $y_{t}$
\end_inset

不是mds，原因
\begin_inset Formula $E_{t-1}[y_{t}]=E_{t-1}[u_{t}+\delta u_{t-1}u_{t-2}]=E_{t-1}[u_{t}]+E_{t-1}[\delta u_{t-1}u_{t-2}]=u_{t}+\delta u_{t-1}u_{t-2}\neq0$
\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection
mixing
\end_layout

\begin_layout Itemize
考虑一个时间序列的两个子样本期序列：
\begin_inset Formula $\stackrel[Y_{-\infty}^{t}]{1st\:sub-period}{\underbrace{\text{...,\ensuremath{y_{t-2}},\ensuremath{y_{t-1}},\ensuremath{y_{t}}}}},y_{t+1},...,y_{t+s-1},\stackrel[Y_{t+s}^{\infty}]{2nd\:sub-period}{\underbrace{\text{\ensuremath{y_{t+s}},\ensuremath{y_{t+s+1}},\ensuremath{y_{t+s+2}},...}}}$
\end_inset

，其中，
\begin_inset Formula $Y_{t}^{s}=(y_{t},y_{t+1},y_{t+2},...,y_{s})$
\end_inset

。如果有：
\begin_inset Formula 
\[
cov[g(Y_{-\infty}^{t}),h(Y_{t+s}^{\infty})]\rightarrow0\quad as\:s\rightarrow\infty\tag{2.2}
\]

\end_inset

（其中，
\begin_inset Formula $g(x)$
\end_inset

和
\begin_inset Formula $h(x)$
\end_inset

是任意的函数）表明，随着时间间隔的增加，它们表现的更像两个独立的随机变量集。满足(2.2)式就被认为是
\begin_inset Formula $mixing$
\end_inset

(technically
\begin_inset Formula $\alpha-mixing$
\end_inset

 or 
\begin_inset Formula $strong\,mixing$
\end_inset

)
\end_layout

\begin_layout Itemize
所有的
\begin_inset Formula $iid$
\end_inset

过程都是
\begin_inset Formula $mixing$
\end_inset

；MA(q)也是
\begin_inset Formula $mixing$
\end_inset

；假定扰动项是正态分布的情况下，AR(1)也是
\begin_inset Formula $mixing$
\end_inset


\end_layout

\begin_layout Subsection
weak law of large numbers(WLLN)
\end_layout

\begin_layout Itemize
之前讨论的随机时间序列都有这样一个特征：概率分布的参数是其矩。极大似然估计中，我们能获得的是样本统计量，因此，我们需要了解当样本容量
\begin_inset Formula $T\rightarrow\infty$
\end_inset

，总体参数和样本统计量之间的关系。
\end_layout

\begin_layout Itemize
example 2.5：exponential distribution
\end_layout

\begin_layout Itemize
弱大数定理的必要条件：总体期望
\begin_inset Formula $μ$
\end_inset

存在(有限)；充分条件：
\begin_inset Formula $E[\bar{y}]\rightarrowμ,var(\bar{y})\rightarrow0\:as\,T\rightarrow\infty$
\end_inset


\end_layout

\begin_layout Itemize
example 2.6：uniform distribution
\end_layout

\begin_layout Itemize
依概率收敛的一些重要性质：
\end_layout

\begin_deeper
\begin_layout Itemize
Property 1：
\begin_inset Formula $plim(\bar{y}_{1}\pm\bar{y}_{2})=plim(\bar{y}_{1})\pm plim(\bar{y}_{2})=μ_{1}+μ_{2}$
\end_inset


\end_layout

\begin_layout Itemize
Property 2：
\begin_inset Formula $plim(\bar{y}_{1}\bar{y}_{2})=plim(\bar{y}_{1})plim(\bar{y}_{2})=μ_{1}μ_{2}$
\end_inset


\end_layout

\begin_layout Itemize
Property 3：
\begin_inset Formula $plim(\frac{\bar{y}_{1}}{\bar{y}_{2}})=\frac{plim(\bar{y}_{1})}{plim(\bar{y}_{2})}=\frac{μ_{1}}{μ_{2}}$
\end_inset


\end_layout

\begin_layout Itemize
Property 4：
\begin_inset Formula $plim\,c(\bar{y})=c(plim(\bar{y}))$
\end_inset

【
\begin_inset Formula $Slutsky's\:theorem$
\end_inset

】
\end_layout

\end_deeper
\begin_layout Itemize
WLLN成立的条件比
\begin_inset Formula $iid$
\end_inset

更弱。在只假定
\begin_inset Formula $var(y_{t})<\infty$
\end_inset

,
\begin_inset Formula $\forall t$
\end_inset

，
\begin_inset Formula $\bar{y}$
\end_inset

的方差总是可以写成
\begin_inset Formula 
\[
var(\bar{y})=\frac{1}{T^{2}}\sum_{t=1}^{T}\sum_{s=1}^{T}cov(y_{t},y_{s})=\frac{1}{T^{2}}\sum_{t=1}^{T}var(\bar{y})+2\frac{1}{T^{2}}\sum_{t=1}^{T}\sum_{t=s+1}^{T}cov(y_{t},y_{t-s})
\]

\end_inset

当
\begin_inset Formula $y_{t}$
\end_inset

是弱平稳时，则有：
\begin_inset Formula 
\[
var(\bar{y})=\frac{1}{T}γ_{0}+2\frac{1}{T}\sum_{s=1}^{T}(1-\frac{s}{T})γ_{s}t\tag{2.6}
\]

\end_inset

其中，
\begin_inset Formula $γ_{s}=cov(y_{t},y_{t-s})$
\end_inset

是
\begin_inset Formula $y_{t}$
\end_inset

的自协方差。
\end_layout

\begin_deeper
\begin_layout Itemize
当
\begin_inset Formula $y_{t}$
\end_inset

是
\begin_inset Formula $iid$
\end_inset

或者
\begin_inset Formula $mds$
\end_inset

或者白噪声时，
\begin_inset Formula $γ_{s}=0,s>0$
\end_inset

，于是式(2.6)为
\begin_inset Formula $var(\bar{y})=\frac{1}{T}γ_{0}\rightarrow0$
\end_inset


\end_layout

\begin_layout Itemize
当
\begin_inset Formula $y_{t}$
\end_inset

存在自相关时，需要额外的充分条件是
\begin_inset Formula $γ_{s}\rightarrow\infty as\,s\rightarrow\infty$
\end_inset

，原因：
\begin_inset Formula 
\[
|\frac{1}{T}\sum_{s=1}^{T}(1-\frac{s}{T})γ_{s}|\leq\frac{1}{T}\sum_{s=1}^{T}(1-\frac{s}{T})|\gamma_{s}|\leq\frac{1}{T}\sum_{s=1}^{T}|\gamma_{s}|\rightarrow0\:as\:T\rightarrow\infty
\]

\end_inset

其中，最后一步用到了
\begin_inset Formula $Cesaro\,summation$
\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
if 
\begin_inset Formula $a_{t}\rightarrow a$
\end_inset

 as 
\begin_inset Formula $t\rightarrow\infty$
\end_inset

,then
\begin_inset Formula $\frac{1}{T}\sum_{t=1}^{T}a_{t}\rightarrow a$
\end_inset

 as 
\begin_inset Formula $T\rightarrow\infty$
\end_inset

 
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
example 2.7：WLLN for an AR(1) model
\end_layout

\begin_layout Subsection
rates of convergence
\end_layout

\begin_layout Itemize
Establishing many of the results of the MLE requires choosing the correct
 scaling factor to ensure that the relevant statistics have non-degenerate
 distributions
\end_layout

\begin_layout Itemize
example 2.8：linear regression with stochastic regressors
\end_layout

\begin_deeper
\begin_layout Itemize
the linear regression model
\begin_inset Formula $y_{t}=\beta x_{t}+u_{t}$
\end_inset

,
\begin_inset Formula $u_{t}\sim iid\,N(0,\sigma^{2})$
\end_inset

，其中
\begin_inset Formula $x_{t}$
\end_inset

是
\begin_inset Formula $iid$
\end_inset

，分布为
\begin_inset Formula $(-0.5,0.5)$
\end_inset

上的均匀分布。
\end_layout

\begin_layout Itemize
\begin_inset Formula $\hat{\beta}=\beta+[\sum_{t=1}^{T}x_{t}^{2}]^{-1}\sum_{t=1}^{T}x_{t}u_{t}$
\end_inset


\end_layout

\begin_layout Itemize
the appropriate scaling of the first moment to ensure that it has a non-degenera
te distribution follows from 
\begin_inset Formula 
\begin{align*}
 & E[\frac{1}{T^{k}}\sum_{t=1}^{T}x_{t}u_{t}]=0\\
 & var(\frac{1}{T^{k}}\sum_{t=1}^{T}x_{t}u_{t})=\frac{1}{T^{2k}}var(\sum_{t=1}^{T}x_{t}u_{t})=T^{1-2k}\sigma_{u}^{2}\sigma_{x}^{2}
\end{align*}

\end_inset

consequently the appropriate choice of scaling factor is 
\begin_inset Formula $k=\frac{1}{2}$
\end_inset

 because 
\begin_inset Formula $T^{-1/2}$
\end_inset

 stabilizes the variace and thus prevents it approaching 
\begin_inset Formula $0(k>1/2)$
\end_inset

 or 
\begin_inset Formula $\infty(k<1/2)$
\end_inset

。
\begin_inset Foot
status open

\begin_layout Plain Layout
注意，上式推导过程中用到了：随机变量X、Y期望为0，且相互独立，则
\begin_inset Formula $var(XY)=E[(XY)^{2}]-[E(XY)]^{2}=E(X^{2}Y^{2})-[E(X)E(Y)]^{2}=E(X^{2})E(Y^{2})=var(X)var(Y)$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
example 2.9：higher-order derivatives
\end_layout

\begin_layout Subsection
central limit theorems(CLT)
\end_layout

\begin_layout Subsubsection
Lindeberg-Levy CLT
\end_layout

\begin_layout Itemize
Let 
\begin_inset Formula $\{y_{1},y_{2},...,y_{T}\}$
\end_inset

 represent a set of T 
\begin_inset Formula $iid$
\end_inset

 random variables from a distribution with finite mean 
\begin_inset Formula $μ$
\end_inset

 and finite variance 
\begin_inset Formula $\sigma^{2}>0$
\end_inset

.
 The Lindeberg-Levy central limit theorem for the scalar case states that
 
\begin_inset Formula $\sqrt{T}(\bar{y}-\mu)\stackrel{d}{\rightarrow}N(0,\sigma^{2})$
\end_inset


\end_layout

\begin_layout Itemize
example 2.10：uniform distribution
\end_layout

\begin_layout Itemize
example 2.11：linear regression with iid regressors
\end_layout

\begin_layout Subsubsection
Lindeberg-Feller CLT
\end_layout

\begin_layout Itemize
the Lindeberg-Feller CLT is applicable to models based on independent and
 non-identically distributed random variables，in which 
\begin_inset Formula $y_{t}$
\end_inset

 has time-varying mean 
\begin_inset Formula $\mu_{t}$
\end_inset

 and time-varying covariance matrix 
\begin_inset Formula $V_{t}$
\end_inset

。
\end_layout

\begin_layout Itemize
For the scalar case, let 
\begin_inset Formula $\{y_{1},y_{2},...,y_{T}\}$
\end_inset

 represent a set of 
\begin_inset Formula $T$
\end_inset

 independent and non-identically distributed random variables from a distributio
n with finite time-varying means 
\begin_inset Formula $E[y_{t}]=\mu_{t}<\infty$
\end_inset

, finite time-varying variances 
\begin_inset Formula $var(y_{t})=\sigma_{t}^{2}<\infty$
\end_inset

and finite higher-order moments。The Lindeberg-Feller CLT gives the necessary
 and sufficient conditons for 
\begin_inset Formula $\sqrt{T}(\frac{\bar{y}-\bar{\mu}}{\bar{\sigma}})\stackrel{d}{\rightarrow}N(0,1)$
\end_inset

, where 
\begin_inset Formula $\bar{\mu}=\frac{1}{T}\sum_{t=1}^{T}\mu_{t}$
\end_inset

, 
\begin_inset Formula $\bar{\sigma^{2}}=\frac{1}{T}\sum_{t=1}^{T}\sigma_{t}^{2}$
\end_inset


\end_layout

\begin_layout Itemize
a sufficient condition for the Lindeberg-Feller CLT is given by 
\begin_inset Formula $E[|y_{t}-\mu_{t}|^{2+\delta}]<\infty,\delta>0$
\end_inset

。this is known as the 
\begin_inset Formula $Lyapunov\,condition$
\end_inset

，which operates on moments higher than the second moment，and this requirement
 is in fact a stricter condition than is needed to satisfy this theorem
\end_layout

\begin_layout Itemize
example 2.12：Bernoulli distribution
\end_layout

\begin_deeper
\begin_layout Itemize
假设
\begin_inset Formula $\{y_{1},y_{2},...,y_{T}\}$
\end_inset

是一列独立的服从Bernoulli分布的随机变量集合，其中，参数
\begin_inset Formula $\theta_{t}$
\end_inset

随时间变化，因此有：
\begin_inset Formula $f(y;\theta_{t})=\theta_{t}^{y}(1-\theta_{t})^{1-y},0<\theta_{t}<1$
\end_inset

，于是：
\begin_inset Formula 
\begin{align*}
 & \mu_{t}=\theta_{t}\\
 & \sigma_{t}^{2}=\theta_{t}(1-\theta_{t})\\
 & E[|y_{t}-\mu_{t}|^{3}]=\theta_{t}(1-\theta_{t})^{3}+(1-\theta_{t})\theta_{t}^{3}=\sigma_{t}^{2}((1-\theta_{t})^{2}+\theta_{t}^{2})\leq\sigma_{t}^{2}\rightarrow\text{有限}
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
example 2.13：linear regression with bounded fixed regressors
\end_layout

\begin_layout Subsubsection
Martingale difference CLT
\end_layout

\begin_layout Itemize
martingale diffenrence CLT本质上还是Lindeberg-Levy CLT只是將“ 
\begin_inset Formula $\{y_{1},y_{2},...,y_{T}\}$
\end_inset

是
\begin_inset Formula $iid$
\end_inset

 ”这一假设换成了更一般的假设：
\begin_inset Formula $y_{t}$
\end_inset

是一个mds，并且
\begin_inset Formula $\bar{y}=\frac{1}{T}\sum_{t=1}^{T}y_{t}$
\end_inset

, 
\begin_inset Formula $\bar{\sigma^{2}}=\frac{1}{T}\sum_{t=1}^{T}\sigma_{t}^{2}$
\end_inset

，高阶矩有界
\begin_inset Formula $E[|y_{t}|^{2+\delta}]<\infty,\delta>0$
\end_inset

，以及
\begin_inset Formula $\frac{1}{T}\sum_{t=1}^{T}y_{t}^{2}-\bar{\sigma^{2}}\stackrel{p}{\rightarrow}0$
\end_inset

，于是
\begin_inset Formula 
\[
\sqrt{T}(\frac{\bar{y}}{\bar{\sigma}})\stackrel{d}{\rightarrow}N(0,1)
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
martingale difference CLT 放松了
\begin_inset Formula $iid$
\end_inset

的假设，但是增加了：样本方差一直腹肌总体平均方差，以及高阶矩有界性(这一点比Lindeberg-Levy CLT要求高)
\end_layout

\end_deeper
\begin_layout Itemize
example 2.14：linear AR(1) model【很好的一个例子】
\end_layout

\begin_layout Subsubsection
mixing CLT
\end_layout

\begin_layout Itemize
如果
\begin_inset Formula $y_{t}$
\end_inset

有零均值，存在某个
\begin_inset Formula $r>2$
\end_inset

使得对于所有的t都有
\begin_inset Formula $E[|y_{t}|^{r}]<\infty$
\end_inset

，并且
\begin_inset Formula $y_{t}$
\end_inset

 is mixing at a sufficiently fast rate，于是有：
\begin_inset Formula 
\[
\frac{1}{\sqrt{T}}\sum_{t=1}^{T}y_{t}\stackrel{d}{\rightarrow}N(0,J)
\]

\end_inset

其中
\begin_inset Formula $J=lim_{T\rightarrow\infty}\frac{1}{T}E[(\sum_{t=1}^{T}y_{t})^{2}]$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
如果
\begin_inset Formula $y_{t}$
\end_inset

是弱平稳序列，则J可以写成
\begin_inset Formula $J=E[y_{t}^{2}]+2\sum_{j=1}^{\infty}E[y_{t}y_{t-j}]=var(y_{t})+2\sum_{j=1}^{\infty}cov(y_{t},y_{t-j})$
\end_inset

，即此时渐进分布的方差依赖于平稳序列的方差以及所有的的自协方差
\end_layout

\end_deeper
\begin_layout Itemize
example 2.15：sample moments of an AR(1) model
\end_layout

\begin_layout Section
regularity conditions
\end_layout

\begin_layout Itemize
假定分布设定是正确的。下面的
\begin_inset Formula $regularity\text{\,}condition$
\end_inset

 适用于
\begin_inset Formula $iid$
\end_inset

、
\begin_inset Formula $stationary$
\end_inset

、
\begin_inset Formula $mds$
\end_inset

 和 
\begin_inset Formula $white\,noise$
\end_inset

 ，以
\begin_inset Formula $iid$
\end_inset

 的情况为例：
\end_layout

\begin_deeper
\begin_layout Itemize
R1: existence
\end_layout

\begin_deeper
\begin_layout Standard
the expection 
\begin_inset Formula $E[lnf(y_{t};\theta)]=\int_{-\infty}^{\infty}lnf(y_{t};\theta)f(y_{t};\theta_{0})dy_{t}$
\end_inset

 exists
\end_layout

\end_deeper
\begin_layout Itemize
R2: convergence
\end_layout

\begin_deeper
\begin_layout Standard
the log-likelihood function converges in probability to its expectation
 
\begin_inset Formula $lnL_{T}(\theta)=\frac{1}{T}\sum_{t=1}^{T}lnf(y_{t};\theta)\stackrel{p}{\rightarrow}E[lnf(y_{t};\theta)]$
\end_inset

 uniformly in 
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
R3: continuity
\end_layout

\begin_deeper
\begin_layout Standard
the log-likelihood function,
\begin_inset Formula $lnL_{T}(\theta)$
\end_inset

, is continuous in 
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
R4: differentiability
\end_layout

\begin_deeper
\begin_layout Standard
the log-likelihood function,
\begin_inset Formula $lnL_{T}(\theta)$
\end_inset

, is at least twice continuously differentiable in an open interval around
 
\begin_inset Formula $\theta_{0}$
\end_inset

【即使似然函数不是处处可导，在某些情况下，仍然可以得到MLE】
\end_layout

\end_deeper
\begin_layout Itemize
R5: interchangeability
\end_layout

\begin_deeper
\begin_layout Standard
the order of differentiation and intergration of 
\begin_inset Formula $lnL_{T}(\theta)$
\end_inset

 is interchangeable【积分与求导过程可以交换(顺序)】
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
example 2.16：likelihood function of the normal distribution
\end_layout

\begin_layout Section
properties of the likelihood function
\end_layout

\begin_layout Subsection
the population of likelihood function
\end_layout

\begin_layout Itemize
在给定R1的前提下，一个重要的性质是，真实值
\begin_inset Formula $\theta_{0}$
\end_inset

最大化了总体似然函数：
\begin_inset Formula 
\[
\theta_{0}=\underset{\theta}{arg\,max}E[lnf(y_{t};\theta)]\tag{2.25}
\]

\end_inset

proof：
\begin_inset Formula 
\begin{align*}
E[lnf(y_{t};\theta)]-E[lnf(y_{t};\theta_{0})] & =E[ln\frac{lnf(y_{t};\theta)}{lnf(y_{t};\theta_{0})}]<lnE[\frac{f(y_{t};\theta)}{f(y_{t};\theta_{0})}]\\
 & =ln\int_{-\infty}^{\infty}\frac{f(y_{t};\theta)}{f(y_{t};\theta_{0})}f(y_{t};\theta_{0})dy_{t}=ln\int_{-\infty}^{\infty}f(y_{t};\theta)dy_{t}=ln1=0
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
example 2.17：population likelihood of the normal distribution
\end_layout

\begin_layout Subsection
moments of the gradient
\end_layout

\begin_layout Itemize
the gradient function 定义为：
\begin_inset Formula 
\[
g_{t}(\theta)=\frac{\partial lnf(y_{t};\theta)}{\partial\theta}\tag{2.26}
\]

\end_inset

它有两个重要性质：
\end_layout

\begin_deeper
\begin_layout Enumerate
mean of the gradient：
\begin_inset Formula $E[g_{t}(\theta_{0})]=0$
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
proof：
\end_layout

\begin_layout Standard
由于
\begin_inset Formula $f(y_{t};\theta)$
\end_inset

是一个概率密度函数，于是
\begin_inset Formula $\int_{-\infty}^{\infty}f(y_{t};\theta)dy_{t}=1$
\end_inset

。
\end_layout

\begin_layout Standard
两边同时对
\begin_inset Formula $\theta$
\end_inset

求导，则
\begin_inset Formula $\frac{\partial}{\partial\theta}(\int_{-\infty}^{\infty}f(y_{t};\theta)dy_{t})=0$
\end_inset

。
\end_layout

\begin_layout Standard
利用R5有
\begin_inset Formula $\int_{-\infty}^{\infty}\frac{\partial}{\partial\theta}(f(y_{t};\theta))dy_{t}=\frac{\partial}{\partial\theta}(\int_{-\infty}^{\infty}f(y_{t};\theta)dy_{t})=0$
\end_inset


\end_layout

\begin_layout Standard
又
\begin_inset Formula $\frac{\partial f(y_{t};\theta)}{\partial\theta}=\frac{\partial lnf(y_{t};\theta)}{\partial\theta}f(y_{t};\theta)=g_{t}(\theta)f(y_{t};\theta)$
\end_inset

，在
\begin_inset Formula $\theta=\theta_{0}$
\end_inset

对应的积分为
\begin_inset Formula $0=\int_{-\infty}^{\infty}\frac{\partial}{\partial\theta}(f(y_{t};\theta_{0}))dy_{t}=\int_{-\infty}^{\infty}g_{t}(\theta_{0})f(y_{t};\theta_{0})dy_{t}=E[g_{t}(\theta_{0})]$
\end_inset

得证
\end_layout

\end_deeper
\begin_layout Enumerate
variance of the gradient：
\begin_inset Formula $var[g_{t}(\theta_{0})]=E[g_{t}(\theta_{0})g_{t}(\theta_{0})^{'}]=-E[h_{t}(\theta_{0})]$
\end_inset

【此式將对数似然函数的一阶导和二阶导联系起来】
\end_layout

\begin_deeper
\begin_layout Standard
proof：
\end_layout

\begin_layout Standard
对
\begin_inset Formula $\int_{-\infty}^{\infty}f(y_{t};\theta)dy_{t}=1$
\end_inset

两边关于
\begin_inset Formula $\theta$
\end_inset

求二阶导
\begin_inset Formula 
\begin{align*}
 & \int_{-\infty}^{\infty}[\frac{\partial lnf(y_{t};\theta)}{\partial\theta}\frac{\partial f(y_{t};\theta)}{\partial\theta^{'}}+\frac{\partial^{2}lnf(y_{t};\theta)}{\partial\theta\partial\theta^{'}}f(y_{t};\theta)]dy_{t}=0\\
\Rightarrow & \int_{-\infty}^{\infty}[\frac{\partial lnf(y_{t};\theta)}{\partial\theta}\frac{\partial lnf(y_{t};\theta)}{\partial\theta^{'}}f(y_{t};\theta)+\frac{\partial^{2}lnf(y_{t};\theta)}{\partial\theta\partial\theta^{'}}f(y_{t};\theta)]dy_{t}=0\\
\Rightarrow & \int_{-\infty}^{\infty}[g_{t}(\theta)g_{t}(\theta)^{'}+h_{t}(\theta)]f(y_{t};\theta)dy_{t}=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
于是，在
\begin_inset Formula $\theta=\theta_{0}$
\end_inset

处，有：
\begin_inset Formula $E[g_{t}(\theta_{0})g_{t}(\theta_{0})^{'}]+E[h_{t}(\theta_{0})]=0$
\end_inset

得证
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
example 2.18：gradient properties and the poisson distribution【很好的例子】
\end_layout

\begin_layout Subsection
the information matrix
\end_layout

\begin_layout Itemize
information matrix 通常定义为 the outer product of the gradients: 
\begin_inset Formula $I(\theta)\equiv E[g_{t}(\theta)g_{t}(\theta)^{'}]\equiv J(\theta)$
\end_inset

。由于
\begin_inset Formula $J(\theta)=-H(\theta)$
\end_inset

，于是
\begin_inset Formula $I(\theta)=-H(\theta)$
\end_inset

，等式成立的前提是分布正确设定，否则等式右侧就是错误计算。
\end_layout

\begin_layout Itemize
利用样本估计总体参数
\begin_inset Formula $\theta_{0}$
\end_inset

，信息矩阵就是对这种样本信息的质量的一种测度。当对数似然函数相对平坦(flat)时，样本信息比较分散，因而用于估计
\begin_inset Formula $\theta_{0}$
\end_inset

的信息不够精确
\end_layout

\begin_deeper
\begin_layout Itemize
如果
\begin_inset Formula $h_{t}(\theta)$
\end_inset

表示在时间点
\begin_inset Formula $t$
\end_inset

可获得的信息，那么总的信息(Total Information,TI)可以通过如下方式计算：
\begin_inset Formula 
\[
TI(\theta_{0})=-\sum_{t=1}^{T}E[h_{t}(\theta_{0})]
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
example 2.19 ：information matrix of the Bernoulli distribution
\end_layout

\begin_layout Itemize
example 2.20：information matrix of the normal distribution
\end_layout

\begin_layout Section
asymptotic properties
\end_layout

\begin_layout Itemize
假定regularity conditions(R1-R5)均成立
\end_layout

\begin_layout Subsection
consistency
\end_layout

\begin_layout Itemize
\begin_inset Formula $plim(\hat{\theta})=\theta_{0}$
\end_inset


\end_layout

\begin_layout Itemize
推导(a heuristic proof，启发式证明)：
\end_layout

\begin_deeper
\begin_layout Standard
假定有T个观测值
\begin_inset Formula $\{y_{1},y_{2},...,y_{T}\}$
\end_inset

，对应的MLE为：
\begin_inset Formula 
\[
\hat{\theta}=\underset{\theta}{arg\,max}\frac{1}{T}\sum_{t=1}^{T}lnf(y_{t};\theta)
\]

\end_inset


\end_layout

\begin_layout Standard
由the convergence regularity condition(R2)：
\begin_inset Formula 
\[
\frac{1}{T}\sum_{t=1}^{T}lnf(y_{t};\theta)\overset{p}{\rightarrow}E[lnf(y_{t};\theta)]
\]

\end_inset


\end_layout

\begin_layout Standard
结合
\begin_inset Formula $\theta_{0}=\underset{\theta}{arg\,max}E[lnf(y_{t};\theta)]$
\end_inset

，有
\begin_inset Formula 
\[
\underset{\theta}{arg\,max}\frac{1}{T}\sum_{t=1}^{T}lnf(y_{t};\theta)\overset{p}{\rightarrow}\underset{\theta}{arg\,max}E[lnf(y_{t};\theta)]
\]

\end_inset


\end_layout

\begin_layout Standard
于是，
\begin_inset Formula $\hat{\theta}\overset{p}{\rightarrow}\theta_{0}$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
两个要点：
\end_layout

\begin_deeper
\begin_layout Itemize
样本对数似然函数收敛到总体对数似然函数
\end_layout

\begin_layout Itemize
样本对数似然函数的最大值收敛到总体对数似然函数的最大值
\end_layout

\end_deeper
\begin_layout Itemize
example 2.21：demonstration of consistency
\end_layout

\begin_layout Itemize
example 2.22：normal distribution
\end_layout

\begin_layout Itemize
example 2.23 cauchy distribution
\end_layout

\begin_layout Subsection
normality
\end_layout

\begin_layout Itemize
首先，一阶条件：
\begin_inset Formula $G_{T}(\hat{\theta})=\frac{1}{T}\sum_{t=1}^{T}g_{t}(\hat{\theta})=0$
\end_inset

，在
\begin_inset Formula $\theta_{0}$
\end_inset

附近泰勒展开：
\begin_inset Formula 
\[
0=\frac{1}{T}\sum_{t=1}^{T}g_{r}(\hat{\theta})=\frac{1}{T}\sum_{t=1}^{T}g_{t}(\theta_{0})+[\frac{1}{T}\sum_{t=1}^{T}h_{t}(\theta^{*})](\hat{\theta}-\theta_{0})\tag{2.37}
\]

\end_inset

其中
\begin_inset Formula $\theta^{*}$
\end_inset

介于
\begin_inset Formula $\theta$
\end_inset

和
\begin_inset Formula $\theta_{0}$
\end_inset

。对上式进行调整，可得
\begin_inset Formula 
\[
\sqrt{T}(\hat{\theta}-\theta_{0})=[-\frac{1}{T}\sum_{t=1}^{T}h_{t}(\theta^{*})]^{-1}[\frac{1}{\sqrt{T}}\sum_{t=1}^{T}g_{t}(\theta_{0})]\tag{2.38}
\]

\end_inset

现在
\begin_inset Formula 
\begin{align*}
\frac{1}{T}\sum_{t=1}^{T}h_{t}(\theta^{*})\overset{p}{\rightarrow}H(\theta_{0})\\
\frac{1}{\sqrt{T}}\sum_{t=1}^{T}g_{t}(\theta_{0})\overset{p}{\rightarrow}N(0,J(\theta_{0})) & \tag{2.39}
\end{align*}

\end_inset

其中
\begin_inset Formula 
\begin{align*}
H(\theta_{0})=\underset{T\rightarrow\infty}{lim}\frac{1}{T}\sum_{t=1}^{T}E[h_{t}(\theta_{0})]\\
J(\theta_{0})=\underset{T\rightarrow\infty}{lim}E[(\frac{1}{\sqrt{T}}\sum_{t=1}^{T}g_{t}(\theta_{0}))(\frac{1}{\sqrt{T}}\sum_{t=1}^{T}g_{t}^{'}(\theta_{0}))]
\end{align*}

\end_inset

结合式(2.38)和(2.39)可得渐进分布：
\begin_inset Formula 
\[
\sqrt{T}(\hat{\theta}-\theta_{0})\overset{d}{\rightarrow}N(0,H^{-1}(\theta_{0})J(\theta_{0})H^{-1}(\theta_{0}))
\]

\end_inset

或
\begin_inset Formula 
\[
\sqrt{T}(\hat{\theta}-\theta_{0})\overset{d}{\rightarrow}N(0,I^{-1}(\theta_{0}))
\]

\end_inset


\end_layout

\begin_layout Itemize
example 2.24： asymptotic normality of the poisson parameter
\end_layout

\begin_layout Itemize
example 2.25：simulating asymptotic normality
\end_layout

\begin_layout Subsection
efficiency
\end_layout

\begin_layout Itemize
Cramer-Rao lower bound：single parameter case
\end_layout

\begin_deeper
\begin_layout Itemize
假定
\begin_inset Formula $\tilde{\theta}$
\end_inset

是
\begin_inset Formula $\theta_{0}$
\end_inset

的一个一致估计量，渐进分布
\begin_inset Formula $\sqrt{T}(\tilde{\theta}-\theta_{0})\overset{d}{\rightarrow}N(0,\varOmega)$
\end_inset

，则Cramer-Rao inequality 表明
\begin_inset Formula $\varOmega\geq\frac{1}{I(\theta_{0})}$
\end_inset

。简单证明如下：
\end_layout

\begin_deeper
\begin_layout Standard
由于估计量是渐进无偏的，即
\begin_inset Formula $E[\tilde{\theta}-\theta_{0}]\rightarrow0$
\end_inset

，也可以：
\begin_inset Formula 
\[
\int...\int(\tilde{\theta}-\theta_{0})f(y_{1},...,y_{T};\theta_{0})dy_{1}...dy_{T}\rightarrow0
\]

\end_inset

两边同时对
\begin_inset Formula $\theta_{0}$
\end_inset

求导，并且利用the interchangeability regularity condition(R5)可得：
\begin_inset Formula 
\[
-\int...\int f(y_{1},...,y_{T};\theta_{0})dy_{1}...dy_{T}+\int...\int(\tilde{\theta}-\theta_{0})\frac{\partial f(y_{1},y_{2},...,y_{T};\theta_{0})}{\partial\theta_{0}}dy_{1}...dy_{T}\rightarrow0
\]

\end_inset

左边第一项为1，所以，上式可调整为
\begin_inset Formula 
\[
\int...\int(\tilde{\theta}-\theta_{0})\frac{\partial f(y_{1},y_{2},...,y_{T};\theta_{0})}{\partial\theta_{0}}dy_{1}...dy_{T}\rightarrow1\tag{2.43}
\]

\end_inset

利用
\begin_inset Formula $\frac{\partial lnf(y_{1},...,y_{t};\theta_{0})}{\partial\theta_{0}}=TG_{T}(\theta_{0})$
\end_inset

，可得
\begin_inset Formula 
\[
cov(\sqrt{T}(\tilde{\theta}-\theta_{0}),\sqrt{T}G_{T}(\theta_{0}))\rightarrow1
\]

\end_inset

由于
\begin_inset Formula $G_{T}(\theta_{0})$
\end_inset

具有零均值，
\begin_inset Formula $\sqrt{T}(\tilde{\theta}-\theta_{0})$
\end_inset

和
\begin_inset Formula $\sqrt{T}G_{T}(\theta_{0})$
\end_inset

之间相关系数的平方为
\begin_inset Formula 
\[
cor(\sqrt{T}(\tilde{\theta}-\theta_{0}),\sqrt{T}G_{T}(\theta_{0}))^{2}=\frac{cov(\sqrt{T}(\tilde{\theta}-\theta_{0}),\sqrt{T}G_{T}(\theta_{0}))^{2}}{var(\sqrt{T}(\tilde{\theta}-\theta_{0}))var(\sqrt{T}G_{T}(\theta_{0}))}\leq1
\]

\end_inset

整理得
\begin_inset Formula 
\[
var(\sqrt{T}(\tilde{\theta}-\theta_{0}))\geq\frac{cov(\sqrt{T}(\tilde{\theta}-\theta_{0}),\sqrt{T}G_{T}(\theta_{0}))^{2}}{var(\sqrt{T}G_{T}(\theta_{0}))}
\]

\end_inset

将不等式两端同时取极限，即得。
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Cramer-Rao lower bound：multiple parameter case
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $\varOmega\geq I^{-1}(\theta_{0})$
\end_inset

或者
\begin_inset Formula $\varOmega-I^{-1}(\theta_{0})$
\end_inset

是一个半正定矩阵
\end_layout

\end_deeper
\begin_layout Itemize
example 2.26：lower bound for the normal distribution
\end_layout

\begin_layout Itemize
example 2.27：relative efficiency of the mean and median
\end_layout

\begin_layout Section
finite-sample properties
\end_layout

\begin_layout Itemize
to approximate the finite sample distribution including simulating the sampling
 distribution by
\begin_inset Formula $Monte\,Carlo\,methods$
\end_inset

 or using an 
\begin_inset Formula $Edgeworth\,expansion\,approach$
\end_inset


\end_layout

\begin_layout Itemize
example 2.28：
\color red
Edgeworth expansion approximations
\end_layout

\begin_layout Subsection
unbiasedness
\end_layout

\begin_layout Itemize
即使样本服从正态分布，也可能出现参数估计有偏，例如
\begin_inset Formula $E[\hat{\sigma}]\neq\sigma_{0}$
\end_inset


\end_layout

\begin_layout Itemize
example 2.29：sample variance of a normal distribution
\end_layout

\begin_layout Subsection
sufficiency
\end_layout

\begin_layout Itemize
充分统计量：利用了样本的所有信息。它意味着联合密度函数可以分解为两部分：
\begin_inset Formula 
\[
f(y_{1},...,y_{T};\theta)=c(\tilde{\theta},\theta)d(y_{1},...,y_{T})\tag{2.45}
\]

\end_inset

，其中，
\begin_inset Formula $\tilde{\theta}$
\end_inset

表示一个关于
\begin_inset Formula $\theta$
\end_inset

的充分统计量。
\end_layout

\begin_layout Itemize
如果充分统计量存在，那么MLE则是关于充分统计量的函数，简单证明如下：
\end_layout

\begin_deeper
\begin_layout Standard
由式(2.45)可得：
\begin_inset Formula $lnL_{T}(\theta)=\frac{1}{T}lnc(\tilde{\theta};\theta)+\frac{1}{T}lnd(y_{1},...,y_{T})$
\end_inset


\end_layout

\begin_layout Standard
两边同时对
\begin_inset Formula $\theta$
\end_inset

求导可得：
\begin_inset Formula $\frac{\partial lnL_{T}(\theta)}{\partial\theta}=\frac{1}{T}\frac{\partial lnc(\tilde{\theta};\theta)}{\partial\theta}$
\end_inset


\end_layout

\begin_layout Standard
MLE
\begin_inset Formula $\hat{\theta}$
\end_inset

使得上式左边等于0，于是：
\begin_inset Formula $\frac{\partial lnc(\tilde{\theta};\hat{\theta})}{\partial\theta}=0$
\end_inset

，整理可得，
\begin_inset Formula $\hat{\theta}$
\end_inset

是充分统计量
\begin_inset Formula $\tilde{\theta}$
\end_inset

的一个函数。
\end_layout

\end_deeper
\begin_layout Itemize
example 2.30：sufficient statistics of the geometric distribution
\end_layout

\begin_layout Subsection
invariance
\end_layout

\begin_layout Itemize
如果
\begin_inset Formula $\hat{\theta}$
\end_inset

是关于
\begin_inset Formula $\theta_{0}$
\end_inset

的MLE，那么对于任何的非线性函数
\begin_inset Formula $\tau(\cdot)$
\end_inset

，
\begin_inset Formula $\tau(\hat{\theta})$
\end_inset

是关于
\begin_inset Formula $\tau(\theta_{0})$
\end_inset

的MLE。
\end_layout

\begin_layout Itemize
example 2.31：invariance property and the normal distribution
\end_layout

\begin_layout Itemize
example 2.32：
\color red
Vasicek interest rate model
\end_layout

\begin_layout Subsection
non-uniqueness
\end_layout

\begin_layout Itemize
目前为止，讨论的最大化对数似然函数的解都是唯一的，而且(多数情况下)是closed-from solution。但是也存在多个解的情况，例如bivariate
 normal distribution
\end_layout

\begin_layout Section

\color red
applications
\end_layout

\begin_layout Chapter
mumerical estimation methods
\end_layout

\begin_layout Section
introduction
\end_layout

\begin_layout Itemize
有许多最大化对数似然函数的解并不是closed-formed solution
\end_layout

\begin_layout Itemize
example 3.1：Cauchy distribution
\end_layout

\begin_layout Itemize
当解析解不存在时，需要求助于数值最优化算法(numerical optimization algorithms)
\end_layout

\begin_layout Section
Newton methods
\end_layout

\begin_layout Itemize
the gradient and Hessian ：
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $G_{T}(\theta)=\frac{\partial lnG_{T}(\theta)}{\partial\theta}=\frac{1}{T}\sum_{t=1}^{T}g_{t}(\theta)$
\end_inset

，
\begin_inset Formula $H_{T}(\theta)=\frac{\partial^{2}lnL_{T}(\theta)}{\partial\theta\partial\theta^{'}}=\frac{1}{T}\sum_{t=1}^{T}h_{t}(\theta)$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
a first-order Taylor series exxpansion of the gradient function around the
 true parameter vector 
\begin_inset Formula $\theta_{0}$
\end_inset

 is：
\begin_inset Formula 
\begin{align*}
 & 0=G_{T}(\hat{\theta})\simeq G_{T}(\theta_{0})+H_{T}(\theta_{0})(\hat{\theta}-\theta_{0})\\
\Rightarrow & \hat{\theta}=\theta_{0}-H_{T}^{-1}(\theta_{0})G_{T}(\theta_{0})\tag{3.3}
\end{align*}

\end_inset

(3.3)式表明MLE是真实值的一个函数。一个很自然的想法是將
\begin_inset Formula $\theta_{0}$
\end_inset

替换成一个初始值并不断迭代，得到MLE，这也是 Newton methods 的基础。下面介绍的几种算法都是基于 Newton methods，不同之处在于对
\begin_inset Formula $Hessian$
\end_inset

 的估计不同。
\end_layout

\begin_layout Subsection
Newton-Raphson
\end_layout

\begin_layout Itemize
假设
\begin_inset Formula $\theta_{(k)}$
\end_inset

表示未知参数的第
\begin_inset Formula $k^{th}$
\end_inset

次迭代。Newton-Raphson algorithm：
\begin_inset Formula 
\[
\theta_{(k)}=\theta_{(k-1)}-H_{(k-1)}^{-1}G_{(k-1)}\tag{3.4}
\]

\end_inset

其中，
\begin_inset Formula $G_{(k)}=\frac{\partial lnL_{T}(\theta)}{\partial\theta}|_{\theta=\theta_{(k)}}$
\end_inset

，
\begin_inset Formula $H_{(k)}=\frac{\partial^{2}lnL_{T}(\theta)}{\partial\theta\partial\theta^{'}}|_{\theta=\theta_{(k)}}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
当
\begin_inset Formula $\theta_{(k)}-\theta_{(k-1)}=-H_{(k-1)}^{-1}G_{(k-1)}\simeq0$
\end_inset

（仅当
\begin_inset Formula $G_{(k)}\simeq G_{(k-1)}\simeq0$
\end_inset

），迭代终止。
\end_layout

\end_deeper
\begin_layout Itemize
example 3.2：exponential distribution: Newton-Raphson
\end_layout

\begin_layout Subsection
method of scoring
\end_layout

\begin_layout Itemize
\begin_inset Formula $method\,of\,scoring$
\end_inset

 利用信息矩阵的性质
\begin_inset Formula 
\[
I(\theta_{0})=-E[h_{t}(\theta_{0})]
\]

\end_inset

于是
\begin_inset Formula 
\[
\theta_{(k)}=\theta_{(k-1)}+I_{(k-1)}^{-1}G_{(k-1)}\tag{3.5}
\]

\end_inset


\end_layout

\begin_layout Itemize
注意：
\begin_inset Formula $Newton\,Raphson\,method$
\end_inset

 是通过
\begin_inset Formula $H_{T}(\theta_{0})=\frac{1}{T}\sum_{t=1}^{T}h_{t}(\theta_{0})$
\end_inset

，即
\begin_inset Formula $h_{t}(\theta_{0})$
\end_inset

的简单平均来计算
\begin_inset Formula $Hessian$
\end_inset

矩阵的；上面的
\begin_inset Formula $method\,of\,scoring$
\end_inset

 是利用
\begin_inset Formula $h_{t}(\theta_{0})$
\end_inset

 的期望来计算信息矩阵的
\end_layout

\begin_layout Itemize
example 3.3：exponential distribution: method of scoring
\end_layout

\begin_layout Itemize
一般来说，相对于
\begin_inset Formula $Newton\,Raphson\,method$
\end_inset

 ，
\begin_inset Formula $method\,of\,scoring$
\end_inset

 需要更少的迭代；但是实际中，很多计量模型很难计算信息矩阵。
\end_layout

\begin_layout Subsection
BHHH algorithm
\end_layout

\begin_layout Itemize
the
\begin_inset Formula $BHHH\,algorithm$
\end_inset

(Berndt, Hall, Hall and Hausman, 1974)利用了信息矩阵等式(information matrix equality)
\begin_inset Formula 
\[
I(\theta_{0})=J(\theta_{0})=E[g_{t}(\theta_{0})g_{t}^{'}(\theta_{0})]\tag{3.6}
\]

\end_inset

將期望替换成样本平均
\begin_inset Formula 
\[
J_{T}(\theta_{0})=\frac{1}{T}\sum_{t=1}^{T}g_{t}(\theta_{0})g_{t}^{'}(\theta_{0})\tag{3.7}
\]

\end_inset

此时，迭代方法变成了
\begin_inset Formula 
\[
\theta_{(k)}=\theta_{(k-1)}+J_{(k-1)}^{-1}G_{(k-1)}\tag{3.8}
\]

\end_inset

其中
\begin_inset Formula $J_{(k)}=\frac{1}{T}\sum_{t=1}^{T}g_{t}(\theta_{(k)})g_{t}^{'}(\theta_{(k)})$
\end_inset


\end_layout

\begin_layout Itemize
example 3.4：exponential distribution: BHHH
\end_layout

\begin_layout Itemize
注意，
\begin_inset Formula $BHHH\,algorithm$
\end_inset

仅要求计算对数似然函数的gradient就可以了，而且gradient的外积保证了矩阵是半正定的；但是，一个劣势在于它可能需要更多次迭代(相对于
\begin_inset Formula $Newton\,Raphson\,method$
\end_inset

 和
\begin_inset Formula $method\,of\,scoring$
\end_inset

)
\end_layout

\begin_layout Itemize
一个很有意思的转化
\end_layout

\begin_deeper
\begin_layout Itemize
令X是一个T*K维矩阵，Y是一个T*1的向量，二者定义如下：
\begin_inset Formula 
\begin{align*}
 & X=\left[\begin{array}{cccc}
\frac{\partial lnl_{1}(\theta)}{\partial\theta_{1}} & \frac{\partial lnl_{1}(\theta)}{\partial\theta_{2}} & \cdots & \frac{\partial lnl_{1}(\theta)}{\partial\theta_{K}}\\
\frac{\partial lnl_{2}(\theta)}{\partial\theta_{1}} & \frac{\partial lnl_{2}(\theta)}{\partial\theta_{2}} & \cdots & \frac{\partial lnl_{2}(\theta)}{\partial\theta_{K}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial lnl_{T}(\theta)}{\partial\theta_{1}} & \frac{\partial lnl_{T}(\theta)}{\partial\theta_{2}} & \cdots & \frac{\partial lnl_{T}(\theta)}{\partial\theta_{K}}
\end{array}\right]\\
 & Y=\left[\begin{array}{c}
1\\
1\\
\vdots\\
1
\end{array}\right]
\end{align*}

\end_inset


\begin_inset Formula $BHHH\,algorithm$
\end_inset

 的迭代算式可以写成
\begin_inset Formula 
\[
\theta_{(k)}=\theta_{(k-1)}+(X_{(k-1)}^{'}X_{(k-1)})^{-1}X_{(k-1)}^{'}Y\tag{3.9}
\]

\end_inset

其中
\begin_inset Formula $J_{(k-1)}=\frac{1}{T}X_{(k-1)}^{'}X_{(k-1)}$
\end_inset

，
\begin_inset Formula $G_{(k-1)}=\frac{1}{T}X_{(k-1)}^{'}Y$
\end_inset


\end_layout

\end_deeper
\begin_layout Subsection
comparative examples
\end_layout

\begin_layout Itemize
example 3.5： Cauchy distribution
\end_layout

\begin_layout Itemize
example 3.6：Weibull distribution
\end_layout

\begin_layout Section
quasi-Newton methods
\end_layout

\begin_layout Itemize
\begin_inset Formula $Newton\,Raphson\,method$
\end_inset

 的一个很明显的特点是：直接计算
\begin_inset Formula $Hessian$
\end_inset

 矩阵；而
\begin_inset Formula $quasi-Newton$
\end_inset

 则使用下面的方法更新
\begin_inset Formula $Hessian$
\end_inset

 矩阵：
\begin_inset Formula 
\[
H_{(k)}=H_{(k-1)}+U_{(k-1)}\tag{3.10}
\]

\end_inset

其中
\begin_inset Formula $U_{(k)}$
\end_inset

是一个更新矩阵，
\begin_inset Formula $quasi-Newton$
\end_inset

 算法不同之处在于对更新矩阵的选择。一个重要的方法是
\begin_inset Formula $BFGS$
\end_inset

算法(Broyden,1970; Fletcher,1970; Goldfarb,1970; Shanno,1970)，其更新矩阵为：
\begin_inset Formula 
\[
U_{(k)}=-\frac{H_{(k)}\Delta_{\theta}\Delta_{G}^{'}+\Delta_{G}\Delta_{\theta}^{'}H_{(k)}}{\Delta_{G}^{'}\Delta_{\theta}}+(1+\frac{\Delta_{\theta}^{'}H_{(k)}\Delta_{\theta}}{\Delta_{G}^{'}\Delta_{\theta}})\frac{\Delta_{G}\Delta_{G}^{'}}{\Delta_{G}^{'}\Delta_{\theta}}
\]

\end_inset

其中
\begin_inset Formula $\Delta_{\theta}=\theta_{(k)}-\theta_{(k-1)}$
\end_inset

，
\begin_inset Formula $\Delta_{G}=G_{(k)}-G_{(k-1)}$
\end_inset


\end_layout

\begin_layout Itemize
example 3.7：exponential distribution using BFGS
\end_layout

\begin_layout Section
line searching
\end_layout

\begin_layout Itemize
在
\begin_inset Formula $\hat{\theta}=\theta_{0}-H_{T}^{-1}(\theta_{0})G_{T}(\theta_{0})$
\end_inset

中，每一次的迭代并不能保证会提高对数似然函数值。为了保证对数似然函数在每一次迭代过程中都能增加，我们引入参数
\begin_inset Formula $\lambda$
\end_inset

以便 control the size of updating
\begin_inset Formula 
\[
\theta_{(k)}=\theta_{(k-1)}-\lambda H_{(k-1)}^{-1}G_{(k-1)},0\leq\lambda\leq1\tag{3.12}
\]

\end_inset

在每一步迭代中，
\begin_inset Formula $\lambda$
\end_inset

都是变化的，而决定每一步迭代中
\begin_inset Formula $\lambda$
\end_inset

的最优值就是一种一维最优化问题，被称为
\begin_inset Formula $line\,searching$
\end_inset

。最简单的方法就是perform a coarse grid search over the possible values（known as
 
\begin_inset Formula $squeezing$
\end_inset

）:
\end_layout

\begin_deeper
\begin_layout Itemize
首先，尝试
\begin_inset Formula $\lambda=1$
\end_inset

，计算对数似然函数值是否增加，若未增加，则尝试
\begin_inset Formula $\lambda=1/2$
\end_inset

；每一步都依此类推
\end_layout

\end_deeper
\begin_layout Itemize
example 3.8：BHHHwith squeezing
\end_layout

\begin_layout Section
optimization based on function evaluation
\end_layout

\begin_layout Itemize
实际中，对数似然函数往往有一个不规则表面(irregular surface)，而且常常会出现 gradient 在许多维度上是平的，在这种情况下数值误差会导致
利用gradient的算法都表现很差。有许多其他仅仅依赖函数值(based solely on function evaluation)的迭代方法，例如
 Nelder and Mead(1965)的单纯形法(simplex method，细节可见Gill, Murray and Wright(1981))以及其
他一些更复杂的方法：模拟退火(simulated annealing)和遗传搜索算法(genetic search algorithms)。这些方法都很稳健，但
是效率都不高。
\end_layout

\begin_layout Itemize

\color red
具体算法待学习
\end_layout

\begin_layout Section
computing standard errors
\end_layout

\begin_layout Itemize
第二章提到，MLE的渐进分布为
\begin_inset Formula $\sqrt{T}(\hat{\theta}-\theta_{0})\overset{d}{\rightarrow}N(0,I^{-1}(\theta_{0}))$
\end_inset

，于是
\begin_inset Formula $\sqrt{T}(\hat{\theta}-\theta_{0})$
\end_inset

的方差-协方差矩阵为
\begin_inset Formula 
\[
\hat{\Omega}=I^{-1}(\hat{\theta})\tag{3.13}
\]

\end_inset

但是现实中，信息矩阵不容易估算，因而常见的是将其替换成
\begin_inset Formula $Hessian$
\end_inset

 矩阵，即
\begin_inset Formula 
\[
\hat{\Omega}=-H_{T}^{-1}(\hat{\theta})\tag{3.14}
\]

\end_inset

如果在MLE处，
\begin_inset Formula $Hessian$
\end_inset

 矩阵并不是负定的，那么标准差将无法计算，此时往往利用the outer product of gradients matrix来替代信息矩阵，即
\begin_inset Formula 
\[
\hat{\Omega}=J_{T}^{-1}(\hat{\theta})\tag{3.15}
\]

\end_inset


\end_layout

\begin_layout Itemize
example 3.9：exponential distribution standard errors
\end_layout

\begin_deeper
\begin_layout Itemize
注意到，使用gradient的外积的计算结果往往与使用信息矩阵或海塞矩阵的结果相差较大，可能的原因是gradient的外积不是对信息矩阵的很好的近似；也有可能是
因为分布错误设定，导致gradient的外积与信息矩阵不收敛到同一个值。
\end_layout

\end_deeper
\begin_layout Itemize
现实中，往往需要估计MLE的某个非线性函数的协方差矩阵，有两种方法：
\begin_inset Formula $substitution\,method$
\end_inset

 和
\begin_inset Formula $delta\,method$
\end_inset

。前者就是简单的将MLE代入非线性函数中，然后利用constrained log-likelihood function去计算标准差。后者则是利用：
\begin_inset Formula 
\[
C(\hat{\theta})=C(\theta_{0})+D(\theta^{*})(\hat{\theta}-\theta_{0})
\]

\end_inset

其中
\begin_inset Formula $D(\theta)=\frac{\partial C(\theta)}{\partial\theta^{'}}$
\end_inset

，
\begin_inset Formula $\theta^{*}$
\end_inset

介于
\begin_inset Formula $\theta_{0}$
\end_inset

和
\begin_inset Formula $\hat{\theta}$
\end_inset

之间。于是
\begin_inset Formula 
\begin{align*}
\sqrt{T}(C(\hat{\theta})-C(\theta_{0})) & =D(\theta^{*})\sqrt{T}(\hat{\theta}-\theta_{0})\\
 & \overset{d}{\rightarrow}D(\theta_{0})\times N(0,I(\theta_{0})^{-1})\\
 & =N(0,D(\theta_{0})I(\theta_{0})^{-1}D(\theta_{0})^{'})
\end{align*}

\end_inset

或者
\begin_inset Formula 
\[
C(\hat{\theta})\stackrel{a}{\rightarrow}N(C(\theta_{0}),\frac{1}{T}D(\theta_{0})I(\theta_{0})^{-1}D(\theta_{0})^{'})
\]

\end_inset

因此，
\begin_inset Formula 
\[
cov(C(\hat{\theta}))=\frac{1}{T}D(\theta_{0})I(\theta_{0})^{-1}D(\theta_{0})^{'}
\]

\end_inset

当然了，信息矩阵也可以依据具体情况用海塞矩阵或者gradient的外积来替代
\end_layout

\begin_layout Itemize
example 3.10：standard errors of nonlinear functions
\end_layout

\begin_layout Section
hints for practical optimization
\end_layout

\begin_layout Subsection
concentrating the likelihood 
\end_layout

\begin_layout Itemize
有时候，可以降低待估参数
\begin_inset Formula $\theta$
\end_inset

的维度，such a reduction is known as 
\begin_inset Formula $concentrating\,the\,likelihoood\,function$
\end_inset

，原因在于部分未知参数可以表示成另外一部分参数的函数
\end_layout

\begin_layout Itemize
example 3.11：Weibull distribution
\end_layout

\begin_layout Subsection
parameter constraints
\end_layout

\begin_layout Itemize
实际中，待估参数往往有一个约束条件，例如方差要求大于0;边际消费倾向要求介于0和1之间等等
\end_layout

\begin_layout Itemize
可以利用一个非线性双射(nonlinear bijective mapping)
\begin_inset Formula $\phi=c(\theta)$
\end_inset

将区间(a,b)映射到real line(当参数一维时；多维时类似)【于是
\begin_inset Formula $\theta=c^{-1}(\phi)$
\end_inset

】。利用ML得到
\begin_inset Formula $\phi$
\end_inset

的MLE
\begin_inset Formula $\hat{\phi}$
\end_inset

之后，利用
\begin_inset Formula $invariance\,property$
\end_inset

可以得到
\begin_inset Formula $\theta$
\end_inset

的MLE
\begin_inset Formula $\hat{\theta}=c^{-1}(\hat{\phi})$
\end_inset


\end_layout

\begin_layout Itemize
一些有用的转换
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Constraint
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Transform：
\begin_inset Formula $\phi=c(\theta)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Inverse Transform：
\begin_inset Formula $\theta=c^{-1}(\phi)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Jacobian 
\begin_inset Formula $\frac{dc(\theta)}{d\theta}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(0,\infty)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=ln\theta$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=e^{\phi}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{\theta}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(-\infty,0)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=ln(-\theta)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=-e^{\phi}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{\theta}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(0,1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=ln(\frac{\theta}{1-\theta})$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=\frac{1}{1+e^{-\phi}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{\theta(1-\theta)}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(0,b)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=ln(\frac{\theta}{b-\theta})$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=\frac{b}{1+e^{-\phi}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{b}{\theta(b-\theta)}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(a,b)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=ln(\frac{\theta-a}{b-\theta})$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=\frac{b+ae^{-\phi}}{1+e^{-\phi}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{b-a}{(\theta-a)(b-\theta)}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(-1,1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=aranh(\theta)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=tan(\phi)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{1-\theta^{2}}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(-1,1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=\frac{\theta}{1-|\theta|}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=\frac{\phi}{1+|\phi|}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{(1-|\theta|)^{2}}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $(-1,1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi=tan(\frac{\pi\theta}{2})$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta=\frac{2}{\pi}tan^{-1}(\phi)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{\pi}{2}sec^{2}(\frac{\pi\theta}{2})$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
注意，在计算标准差时需要使用
\begin_inset Formula $substitution$
\end_inset

或者
\begin_inset Formula $delta\,method$
\end_inset


\end_layout

\begin_layout Subsection
choice of algorithm
\end_layout

\begin_layout Itemize
本章讨论的方法在最优值附近的收敛速度都是二次的，即
\begin_inset Formula $\bigparallel\theta_{(k+1)}-\theta\bigparallel<\kappa\bigparallel\theta_{(k)}-\theta\bigparallel^{2},\kappa>0$
\end_inset


\end_layout

\begin_layout Itemize
几点注意
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $Newton-Raphson$
\end_inset

 和
\begin_inset Formula $method\,of\,scoring$
\end_inset

需要对数似然函数的前两阶导数；而且由于信息矩阵很难计算，所以
\begin_inset Formula $method\,of\,scoring$
\end_inset

仅仅具有理论上优势而已。
\end_layout

\begin_layout Itemize
\begin_inset Formula $Newton-Raphson$
\end_inset

方法虽然在最优值附近收敛速度是二次的，但是，比较而言，它所估计的最优值往往离真实值最远。因而通过数值计算的海塞矩阵可能不是负定的，从而导致算法不稳定。
\end_layout

\begin_layout Itemize
由于
\begin_inset Formula $BHHH$
\end_inset

 使用gradient的外积，从而保证了半正定，因而许多计量问题都选择它作为主要算法
\end_layout

\begin_layout Itemize
目前的共识是
\begin_inset Formula $quasi-Newton$
\end_inset

算法是更好的选择。更新海塞矩阵时所用的
\begin_inset Formula $BFGS$
\end_inset

算法的结果很稳健，因此，实际应用中，许多都会默认使用
\begin_inset Formula $BFGS$
\end_inset

算法。
\end_layout

\begin_layout Itemize
一个
\color red
广泛应用的策略
\color inherit
是：先使用单纯形法开始进行数值最优化，经过几步迭代后，使用
\begin_inset Formula $BFGS$
\end_inset

算法加速收敛速度。
\end_layout

\end_deeper
\begin_layout Subsection
numerical derivatives
\end_layout

\begin_layout Itemize
1st-order numerical derivatives：
\begin_inset Formula $\frac{\partial lnL_{T}(\theta)}{\partial\theta}|_{\theta=\theta_{(k)}}\simeq\frac{lnL(\theta_{(k)}+s)-lnL(\theta_{(k)})}{s}$
\end_inset


\end_layout

\begin_layout Itemize
2nd-order numerical derivatives：
\begin_inset Formula $\frac{\partial^{2}lnL_{T}(\theta)}{\partial\theta^{2}}|_{\theta=\theta_{(k)}}\simeq\frac{lnL(\theta_{(k)}+s)-2lnL(\theta_{(k)})+lnL(\theta_{(k)}-s)}{s^{2}}$
\end_inset


\end_layout

\begin_layout Subsection
starting values
\end_layout

\begin_layout Itemize
arbitrary choice，当对数似然函数是globally concave时。例如一些情况下，初始值选择0会导致多重共线问题。
\end_layout

\begin_layout Itemize
consistent estimator，前提是可以获得consistent estimator。这种方法的好处就是每次迭代结果都是一致估计量
\end_layout

\begin_layout Itemize
restricted model
\end_layout

\begin_layout Itemize
historical precedent
\end_layout

\begin_layout Subsection
convergence criteria
\end_layout

\begin_layout Itemize
给定收敛精度(convergence tolerance)
\begin_inset Formula $\varepsilon$
\end_inset

，一些普遍使用的判断收敛的标准：
\end_layout

\begin_deeper
\begin_layout Itemize
objective function：
\begin_inset Formula $lnL(\theta_{(k)})-lnL(\theta_{(k-1)})<\varepsilon$
\end_inset


\end_layout

\begin_layout Itemize
gradient function:
\begin_inset Formula $G(\theta_{(k)})^{'}G(\theta_{(k)})<\varepsilon$
\end_inset


\end_layout

\begin_layout Itemize
parameter values：
\begin_inset Formula $(\theta_{(k)})^{'}(\theta_{(k)})<\varepsilon$
\end_inset


\end_layout

\begin_layout Itemize
updating function：
\begin_inset Formula $G(\theta_{(k)})^{'}H(\theta_{(k)})^{-1}G(\theta_{(k)})<\varepsilon$
\end_inset


\end_layout

\end_deeper
\begin_layout Section
applications
\end_layout

\end_body
\end_document
